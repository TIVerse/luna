# ğŸŒ™ LUNA Voice Assistant

A privacy-first, offline voice-controlled desktop assistant written in Rust.

## Features

- ğŸ¤ **Always Listening**: Wake word detection with "Hey Luna"
- ğŸ§  **Natural Language**: Understands conversational commands
- ğŸ”’ **Privacy First**: 100% offline, zero cloud dependencies
- âš¡ **Fast**: Sub-second response times
- ğŸ–¥ï¸ **Cross-Platform**: Windows, Linux, and macOS support

## Current Status

**Phase 1: Foundation** âœ… **COMPLETE**
- Configuration system with TOML support
- Comprehensive error handling framework
- Logging infrastructure with file rotation
- Core utilities (string matching, path helpers)
- Database schemas for apps and files
- Complete project structure with module stubs

**Phase 2: Audio System** ğŸš§ Pending
**Phase 3: Brain/NLP** ğŸš§ Pending
**Phase 4: Action Execution** ğŸš§ Pending
**Phase 5: OS Integration** ğŸš§ Pending
**Phase 6: TTS & Context** ğŸš§ Pending
**Phase 7: Integration** ğŸš§ Pending

## Quick Start

### Prerequisites

```bash
# Install Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Linux dependencies
sudo apt install libasound2-dev portaudio19-dev

# macOS dependencies
brew install portaudio
```

### Build and Run

```bash
# Clone repository
git clone <repository-url>
cd luna

# Build
cargo build --release

# Run
cargo run --release
```

## Configuration

Edit `config/default.toml` to customize settings:

```toml
[audio]
wake_words = ["hey luna", "okay luna"]
sample_rate = 16000

[system]
log_level = "info"
```

## Project Structure

```
luna/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs              # Entry point
â”‚   â”œâ”€â”€ lib.rs               # Library root
â”‚   â”œâ”€â”€ config.rs            # Configuration âœ…
â”‚   â”œâ”€â”€ error.rs             # Error handling âœ…
â”‚   â”œâ”€â”€ utils.rs             # Utilities âœ…
â”‚   â”œâ”€â”€ audio/               # Audio system (Phase 2)
â”‚   â”œâ”€â”€ brain/               # NLP system (Phase 3)
â”‚   â”œâ”€â”€ actions/             # Action executor (Phase 4)
â”‚   â”œâ”€â”€ os/                  # OS integration (Phase 5)
â”‚   â”œâ”€â”€ tts/                 # Text-to-speech (Phase 6)
â”‚   â”œâ”€â”€ context/             # Context manager (Phase 6)
â”‚   â””â”€â”€ db/                  # Databases âœ…
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default.toml         # Configuration file
â”œâ”€â”€ models/                  # AI models directory
â””â”€â”€ docs/                    # Documentation

âœ… = Implemented in Phase 1
```

## Development

### Run Tests

```bash
cargo test
```

### Build Documentation

```bash
cargo doc --open
```

### Check Code

```bash
cargo clippy
cargo fmt --check
```

## Phase 1 Implementation

Phase 1 establishes the foundation:

- âœ… Complete project structure (40+ files)
- âœ… Configuration system with validation
- âœ… Error handling with custom types
- âœ… Logging with tracing
- âœ… Core utilities (fuzzy matching, path helpers, time parsing)
- âœ… Database schemas (Application, FileEntry)
- âœ… Module stubs for future phases

## Next Steps

Proceed to **Phase 2: Audio System** to implement:
- Microphone capture with cpal
- Wake word detection with Porcupine
- Speech-to-text with Whisper AI
- Audio preprocessing (VAD, noise reduction)

See `docs/prompt-part2-audio.md` for detailed instructions.

## License

MIT

## Contributing

Contributions welcome! Please read CONTRIBUTING.md first.

## Support

- ğŸ“š Documentation: `docs/`
- ğŸ› Issues: GitHub Issues
- ğŸ’¬ Discussions: GitHub Discussions
